/*
 *    GeoTools - The Open Source Java GIS Toolkit
 *    http://geotools.org
 *
 *    (C) 2002-2025, Open Source Geospatial Foundation (OSGeo)
 *
 *    This library is free software; you can redistribute it and/or
 *    modify it under the terms of the GNU Lesser General Public
 *    License as published by the Free Software Foundation;
 *    version 2.1 of the License.
 *
 *    This library is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 *    Lesser General Public License for more details.
 */
package org.geotools.data.geoparquet;

import static java.lang.String.format;
import static java.util.Objects.requireNonNull;

import java.io.File;
import java.io.IOException;
import java.net.URI;
import java.nio.charset.StandardCharsets;
import java.sql.Blob;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.logging.Level;
import java.util.logging.Logger;
import java.util.stream.Collectors;
import org.apache.commons.lang3.StringUtils;
import org.geotools.api.data.Transaction;
import org.geotools.api.feature.simple.SimpleFeatureType;
import org.geotools.api.feature.type.GeometryDescriptor;
import org.geotools.api.referencing.crs.CoordinateReferenceSystem;
import org.geotools.data.duckdb.DuckDBDialect;
import org.geotools.data.jdbc.FilterToSQL;
import org.geotools.geometry.jts.ReferencedEnvelope;
import org.geotools.jdbc.AutoGeneratedPrimaryKeyColumn;
import org.geotools.jdbc.JDBCDataStore;
import org.geotools.jdbc.PrimaryKey;
import org.geotools.jdbc.PrimaryKeyColumn;
import org.geotools.jdbc.PrimaryKeyFinder;
import org.geotools.util.logging.Logging;
import org.locationtech.jts.geom.Geometry;

/**
 * SQL Dialect for GeoParquet format.
 *
 * <p>This dialect extends the base DuckDB dialect with GeoParquet-specific functionality:
 *
 * <ul>
 *   <li>Parsing and utilizing GeoParquet metadata from the "geo" field
 *   <li>Setting up appropriate SQL views for GeoParquet files
 *   <li>Optimizing spatial operations and bounds computations
 *   <li>Handling both local and remote (HTTP, S3) GeoParquet data access
 * </ul>
 *
 * <p>The dialect extracts and uses the GeoParquet specification metadata to provide improved performance for operations
 * like bounds computation and feature access. It supports both standard GeoParquet format (1.1.0) and development
 * versions (1.2.0-dev).
 */
public class GeoParquetDialect extends DuckDBDialect {

    private static final Logger LOGGER = Logging.getLogger(GeoParquetDialect.class);

    /** The URI of the GeoParquet file or directory being accessed */
    private final URI uri;

    /** Cached GeoParquet metadata extracted from the dataset */
    private GeoparquetDatasetMetadata geoparquetMetadata;

    public GeoParquetDialect(JDBCDataStore dataStore, URI uri) {
        super(dataStore);
        this.uri = uri;
    }

    @Override
    public FilterToSQL createFilterToSQL() {
        return new GeoParquetFilterToSQL();
    }

    /** Database init scripts to work with geoparquet */
    @Override
    public List<String> getDatabaseInitSql() {
        List<String> initScript = new ArrayList<>(super.getDatabaseInitSql());
        initScript.add("install httpfs");
        initScript.add("load httpfs");
        initScript.add("install parquet");
        initScript.add("load parquet");
        return initScript;
    }

    public GeoparquetDatasetMetadata getGeoparquetMetadata(Connection cx) throws IOException {
        if (geoparquetMetadata == null) {
            Map<String, GeoParquetMetadata> md = loadGeoparquetMetadata(cx);
            geoparquetMetadata = new GeoparquetDatasetMetadata(md);
        }
        return geoparquetMetadata;
    }

    public Map<String, GeoParquetMetadata> loadGeoparquetMetadata(Connection cx) throws IOException {
        String lookUpUri = isDirectory(uri)
                ? toFile(uri)
                        .map(File::getAbsolutePath)
                        .map(dir -> dir + "/*.parquet")
                        .orElseThrow()
                : uri.toASCIIString();
        // geo comes as a binary string
        String sql = format(
                "SELECT file_name, value::BLOB AS value FROM parquet_kv_metadata('%s') WHERE key = 'geo'", lookUpUri);

        Map<String, GeoParquetMetadata> parquetMetadataByFileName = new HashMap<>();
        try (Statement st = cx.createStatement();
                ResultSet rs = st.executeQuery(sql)) {
            while (rs.next()) {
                String fileName = rs.getString("file_name");
                Blob blobData = rs.getBlob("value");
                GeoParquetMetadata md = parseMetadata(fileName, blobData);
                if (md != null) {
                    parquetMetadataByFileName.put(fileName, md);
                }
            }
        } catch (SQLException e) {
            throw new IOException(e);
        }

        return parquetMetadataByFileName;
    }

    private GeoParquetMetadata parseMetadata(String fileName, Blob blobData) throws SQLException {
        long length = blobData.length();
        byte[] bytes = blobData.getBytes(1L /* yes, 1-indexed */, (int) length);
        String json = new String(bytes, StandardCharsets.UTF_8);
        try {
            return GeoParquetMetadata.readValue(json);
        } catch (IOException e) {
            LOGGER.log(
                    Level.SEVERE,
                    e,
                    () -> format("Error parsing geoparquet metadata. File: %s, geo: %s", fileName, blobData));
        }
        return null;
    }

    /**
     * Helper for {@link GeoParquetDataStoreFactory} to identify the {@code id} column as the primary key (and hence the
     * FeatureId)
     */
    public PrimaryKeyFinder getPrimaryKeyFinder() {
        return new PrimaryKeyFinder() {
            @Override
            public PrimaryKey getPrimaryKey(JDBCDataStore store, String schema, String table, Connection cx) {
                List<PrimaryKeyColumn> columns = List.of(new AutoGeneratedPrimaryKeyColumn("id", String.class));
                return new PrimaryKey(table, columns);
            }
        };
    }

    //

    /**
     * If possible, return the full dataset bounds from the {@code geo} geoparquet metadata field.
     *
     * <p>Otherwise check if there's a {@code bbox} column even if the geoparquet metadata is not present (e.g.
     * OvertureMaps release 2025-02-19.0), and compute the xmin,xmax,ymin,ymax bounds using aggregate functions, which
     * will perform better since it uses the column stats.
     *
     * <p>Finally, fall back to {@link DuckDBDialect#getOptimizedBounds(String, SimpleFeatureType, Connection)} for a
     * more general (and slow) {@code ST_Extent_Agg(geometry)} call.
     */
    @Override
    public List<ReferencedEnvelope> getOptimizedBounds(String schema, SimpleFeatureType featureType, Connection cx)
            throws SQLException, IOException {

        if (null == featureType.getGeometryDescriptor()) {
            return List.of();
        }

        GeoparquetDatasetMetadata md = getGeoparquetMetadata(cx);
        ReferencedEnvelope bounds;
        if (!md.isEmpty()) {
            bounds = md.getBounds();
        } else if (featureType.getDescriptor("bbox") != null) {
            // no geoparquet metadata ('geo' key present), see if there's a 'bbox' column
            // anyways
            bounds = computeBoundsFromBboxColumn(featureType, cx);
        } else {
            // fall back to ST_Extent_Agg(geometry)
            bounds = super.optimizedBounds(featureType, cx);
        }
        return List.of(requireNonNull(bounds));
    }

    private ReferencedEnvelope computeBoundsFromBboxColumn(SimpleFeatureType featureType, Connection cx)
            throws SQLException, IOException {

        String sql = format(
                "SELECT ST_AsWKB(ST_MakeEnvelope(MIN(bbox.xmin), MAX(bbox.xmax), MIN(bbox.ymin), MAX(bbox.ymax))::GEOMETRY)::BLOB FROM %s",
                escapeName(featureType.getTypeName()));

        try (PreparedStatement ps = cx.prepareStatement(sql);
                ResultSet rs = ps.executeQuery()) {
            rs.next();
            Geometry fullBounds = parseWKB(rs.getBlob(1));
            GeometryDescriptor geometryDescriptor = featureType.getGeometryDescriptor();
            CoordinateReferenceSystem crs = geometryDescriptor.getCoordinateReferenceSystem();
            return new ReferencedEnvelope(fullBounds.getEnvelopeInternal(), crs);
        }
    }

    public void registerParquetViews() throws IOException {
        try (Connection c = dataStore.getConnection(Transaction.AUTO_COMMIT)) {
            registerParquetViews(c);
        } catch (SQLException e) {
            throw new IOException(e);
        }
    }

    private void registerParquetViews(Connection c) throws SQLException {
        try (Statement st = c.createStatement()) {
            for (String viewSql : registerGeoParquetSource()) {
                st.addBatch(viewSql);
            }
            st.executeBatch();
        }
    }

    private List<String> registerGeoParquetSource() {
        Optional<File> file = toFile(uri);
        if (file.isPresent()) {
            List<File> parquetFiles = findParquetFiles(file.orElseThrow());
            return registerParquetFiles(parquetFiles);
        }
        return List.of(createParquetUrlView(uri));
    }

    @Override
    public Integer getGeometrySRID(String schemaName, String tableName, String columnName, Connection cx)
            throws SQLException {

        return 4326;
    }

    private boolean isDirectory(URI uri) {
        return toFile(uri).map(File::isDirectory).orElse(false);
    }

    private Optional<File> toFile(URI uri) {
        if (StringUtils.isEmpty(uri.getScheme())) {
            uri = URI.create("file:" + uri);
        }
        if ("file".equals(uri.getScheme())) {
            File file = new File(uri).getAbsoluteFile();
            return Optional.of(file);
        }
        return Optional.empty();
    }

    /** List of files as absolute path names */
    private List<File> findParquetFiles(File file) {

        if (!file.isAbsolute()) file = file.getAbsoluteFile();
        if (file.isDirectory()) {
            File[] parquetFiles = file.listFiles((d, name) -> name.toLowerCase().endsWith(".parquet"));
            if (parquetFiles == null || parquetFiles.length == 0) {
                throw new IllegalArgumentException("No parquet files found in directory: " + file);
            }
            return Arrays.asList(parquetFiles);
        }
        return List.of(file);
    }

    private List<String> registerParquetFiles(List<File> parquetFiles) {
        // Create a view for each parquet file
        return parquetFiles.stream().map(this::createParquetView).collect(Collectors.toList());
    }

    private String createParquetView(File parquetFile) {
        String viewName = generateViewName(parquetFile.getName());
        String filePath = parquetFile.getAbsolutePath();

        return format(
                "CREATE VIEW IF NOT EXISTS %s AS SELECT * FROM read_parquet('%s')", escapeName(viewName), filePath);
    }

    private String createParquetUrlView(URI uri) {
        String path = uri.getPath();
        String viewName = generateViewName(path.substring(path.lastIndexOf('/') + 1));

        return format("CREATE VIEW IF NOT EXISTS %s AS SELECT * FROM read_parquet('%s')", escapeName(viewName), uri);
    }

    private String generateViewName(String filename) {
        String replaceAll = filename.replaceAll("\\.parquet$", "").replaceAll("[^\\w]", "_");
        return replaceAll;
    }
}
