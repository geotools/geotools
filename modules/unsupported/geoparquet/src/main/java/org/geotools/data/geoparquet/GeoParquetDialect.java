/*
 *    GeoTools - The Open Source Java GIS Toolkit
 *    http://geotools.org
 *
 *    (C) 2002-2025, Open Source Geospatial Foundation (OSGeo)
 *
 *    This library is free software; you can redistribute it and/or
 *    modify it under the terms of the GNU Lesser General Public
 *    License as published by the Free Software Foundation;
 *    version 2.1 of the License.
 *
 *    This library is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 *    Lesser General Public License for more details.
 */
package org.geotools.data.geoparquet;

import static java.lang.String.format;
import static java.util.Objects.requireNonNull;

import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.sql.Blob;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;
import java.util.logging.Level;
import java.util.logging.Logger;
import org.geotools.api.feature.simple.SimpleFeatureType;
import org.geotools.api.feature.type.GeometryDescriptor;
import org.geotools.api.referencing.crs.CoordinateReferenceSystem;
import org.geotools.data.duckdb.DuckDBDialect;
import org.geotools.data.jdbc.FilterToSQL;
import org.geotools.geometry.jts.ReferencedEnvelope;
import org.geotools.jdbc.AutoGeneratedPrimaryKeyColumn;
import org.geotools.jdbc.JDBCDataStore;
import org.geotools.jdbc.PrimaryKey;
import org.geotools.jdbc.PrimaryKeyColumn;
import org.geotools.jdbc.PrimaryKeyFinder;
import org.geotools.util.logging.Logging;
import org.locationtech.jts.geom.Geometry;

/**
 * SQL Dialect for GeoParquet format.
 *
 * <p>This dialect extends the base DuckDB dialect with GeoParquet-specific functionality:
 *
 * <ul>
 *   <li>Parsing and utilizing GeoParquet metadata from the "geo" field
 *   <li>Setting up appropriate SQL views for GeoParquet files
 *   <li>Optimizing spatial operations and bounds computations
 *   <li>Handling both local and remote (HTTP, S3) GeoParquet data access
 * </ul>
 *
 * <p>The dialect extracts and uses the GeoParquet specification metadata to provide improved performance for operations
 * like bounds computation and feature access. It supports both standard GeoParquet format (1.1.0) and development
 * versions (1.2.0-dev).
 *
 * <p>The dialect uses several performance optimizations:
 *
 * <ul>
 *   <li>Extracting bounds from GeoParquet metadata rather than computing them
 *   <li>Creating SQL views for consistent access to partitioned datasets
 *   <li>Using DuckDB's spatial functions for efficient querying
 *   <li>Maintaining a cache of metadata to avoid repeated parsing
 * </ul>
 *
 * <p>It works in conjunction with {@link GeoParquetViewManager} to handle Hive-partitioned datasets, exposing each
 * partition as a separate feature type.
 */
public class GeoParquetDialect extends DuckDBDialect {

    private static final Logger LOGGER = Logging.getLogger(GeoParquetDialect.class);

    private final GeoParquetViewManager viewManager;

    /** Cached GeoParquet metadata extracted from the dataset */
    private Map<String, GeoparquetDatasetMetadata> geoparquetMetadata = new ConcurrentHashMap<>();

    /**
     * Creates a new GeoParquetDialect.
     *
     * @param dataStore The JDBC datastore this dialect will work with
     */
    public GeoParquetDialect(JDBCDataStore dataStore) {
        super(dataStore);
        this.viewManager = new GeoParquetViewManager(dataStore);
    }

    /**
     * Creates a specialized filter-to-SQL converter for GeoParquet.
     *
     * @return A new GeoParquetFilterToSQL instance
     */
    @Override
    public FilterToSQL createFilterToSQL() {
        return new GeoParquetFilterToSQL();
    }

    /**
     * Provides SQL statements to initialize the DuckDB database for GeoParquet access.
     *
     * <p>This installs and loads required DuckDB extensions:
     *
     * <ul>
     *   <li>httpfs - For HTTP/S3 access to remote GeoParquet files
     *   <li>parquet - For reading Parquet file format
     * </ul>
     *
     * @return List of SQL statements to initialize the database
     */
    @Override
    public List<String> getDatabaseInitSql() {
        List<String> initScript = new ArrayList<>(super.getDatabaseInitSql());
        initScript.add("install httpfs");
        initScript.add("load httpfs");
        initScript.add("install parquet");
        initScript.add("load parquet");
        return initScript;
    }

    /**
     * Registers SQL views for GeoParquet data partitions.
     *
     * <p>This method is called by {@link GeoParquetDataStoreFactory#setupDataStore(JDBCDataStore, Map)} to initialize
     * the dialect with the provided configuration. It:
     *
     * <ol>
     *   <li>Clears any cached metadata
     *   <li>Initializes the view manager with the new configuration
     * </ol>
     *
     * @param config The GeoParquet configuration
     * @throws IOException If there's an error registering the views
     */
    public void registerParquetViews(GeoParquetConfig config) throws IOException {
        geoparquetMetadata.clear();
        viewManager.initialize(config);
    }

    /**
     * Gets the GeoParquet metadata for a feature type.
     *
     * <p>This method retrieves metadata from the cache if available, or loads it from the data source if not yet
     * cached.
     *
     * @param featureType The feature type to get metadata for
     * @param cx Database connection to use if metadata needs to be loaded
     * @return The GeoParquet metadata for the feature type
     * @throws IOException If there's an error accessing the metadata
     */
    GeoparquetDatasetMetadata getGeoparquetMetadata(SimpleFeatureType featureType, Connection cx) throws IOException {

        final String viewName = featureType.getTypeName();
        return geoparquetMetadata.computeIfAbsent(viewName, view -> loadGeoparquetMetadata(viewName, cx));
    }

    /**
     * Loads GeoParquet metadata for a specific view.
     *
     * <p>This method:
     *
     * <ol>
     *   <li>Retrieves the URI for the view
     *   <li>Queries the Parquet key-value metadata to extract the 'geo' field
     *   <li>Parses the metadata for each file in the dataset
     * </ol>
     *
     * @param viewName The name of the view to load metadata for
     * @param cx Database connection to use for querying
     * @return The combined dataset metadata
     */
    public GeoparquetDatasetMetadata loadGeoparquetMetadata(String viewName, Connection cx) {

        String lookUpUri = viewManager.getVieUri(viewName);
        // geo comes as a binary string
        String sql = format(
                "SELECT file_name, value::BLOB AS value FROM parquet_kv_metadata('%s') WHERE key = 'geo'", lookUpUri);

        Map<String, GeoParquetMetadata> parquetMetadataByFileName = new HashMap<>();
        try (Statement st = cx.createStatement();
                ResultSet rs = st.executeQuery(sql)) {
            while (rs.next()) {
                String fileName = rs.getString("file_name");
                Blob blobData = rs.getBlob("value");
                GeoParquetMetadata md = parseMetadata(fileName, blobData);
                if (md != null) {
                    parquetMetadataByFileName.put(fileName, md);
                }
            }
        } catch (SQLException e) {
            throw new IllegalStateException(e);
        }

        return new GeoparquetDatasetMetadata(parquetMetadataByFileName);
    }

    /**
     * Parses the 'geo' metadata blob from a Parquet file into a structured object.
     *
     * <p>This method:
     *
     * <ol>
     *   <li>Extracts the binary data from the blob
     *   <li>Converts it to a UTF-8 string (the geo metadata is stored as JSON)
     *   <li>Parses the JSON into a GeoParquetMetadata object
     * </ol>
     *
     * @param fileName The name of the file this metadata belongs to
     * @param blobData The binary 'geo' metadata
     * @return The parsed metadata, or null if parsing failed
     */
    private GeoParquetMetadata parseMetadata(String fileName, Blob blobData) throws SQLException {
        long length = blobData.length();
        byte[] bytes = blobData.getBytes(1L /* yes, 1-indexed */, (int) length);
        String json = new String(bytes, StandardCharsets.UTF_8);
        try {
            return GeoParquetMetadata.readValue(json);
        } catch (IOException e) {
            LOGGER.log(
                    Level.SEVERE,
                    e,
                    () -> format("Error parsing geoparquet metadata. File: %s, geo: %s", fileName, blobData));
        }
        return null;
    }

    /**
     * Provides a PrimaryKeyFinder that identifies the 'id' column as the primary key.
     *
     * <p>This is a helper for {@link GeoParquetDataStoreFactory} to establish the feature ID column in GeoParquet
     * datasets. It always identifies the 'id' column as a String primary key, which is the standard convention for
     * GeoParquet files.
     *
     * @return A PrimaryKeyFinder for GeoParquet datasets
     */
    public PrimaryKeyFinder getPrimaryKeyFinder() {
        return new PrimaryKeyFinder() {
            @Override
            public PrimaryKey getPrimaryKey(JDBCDataStore store, String schema, String table, Connection cx) {
                List<PrimaryKeyColumn> columns = List.of(new AutoGeneratedPrimaryKeyColumn("id", String.class));
                return new PrimaryKey(table, columns);
            }
        };
    }

    /**
     * Returns optimized bounds for a feature type by using GeoParquet metadata.
     *
     * <p>This method uses a multi-stage approach to efficiently determine dataset bounds:
     *
     * <ol>
     *   <li>First tries to extract bounds from the GeoParquet 'geo' metadata field
     *   <li>If 'geo' metadata is not available, checks for a 'bbox' column and uses aggregate functions on its
     *       components (common in datasets like OvertureMaps)
     *   <li>Finally falls back to the generic DuckDB bounds computation using spatial functions
     * </ol>
     *
     * <p>Each method is progressively more computationally expensive, so we try them in order of efficiency.
     *
     * @param schema The database schema (unused in GeoParquet)
     * @param featureType The feature type to get bounds for
     * @param cx Database connection to use for querying
     * @return A list containing a single ReferencedEnvelope representing the dataset bounds
     * @throws SQLException If there's an error executing SQL
     * @throws IOException If there's an error accessing the data
     */
    @Override
    public List<ReferencedEnvelope> getOptimizedBounds(String schema, SimpleFeatureType featureType, Connection cx)
            throws SQLException, IOException {

        if (null == featureType.getGeometryDescriptor()) {
            return List.of();
        }

        GeoparquetDatasetMetadata md = getGeoparquetMetadata(featureType, cx);
        ReferencedEnvelope bounds;
        if (!md.isEmpty()) {
            bounds = md.getBounds();
        } else if (featureType.getDescriptor("bbox") != null) {
            // no geoparquet metadata ('geo' key present), see if there's a 'bbox' column
            // anyways
            bounds = computeBoundsFromBboxColumn(featureType, cx);
        } else {
            // fall back to ST_Extent_Agg(geometry)
            bounds = super.optimizedBounds(featureType, cx);
        }
        return List.of(requireNonNull(bounds));
    }

    /**
     * Computes bounds from a 'bbox' column in the dataset.
     *
     * <p>This method handles datasets that don't have GeoParquet 'geo' metadata but do have a 'bbox' column with xmin,
     * xmax, ymin, ymax components. It uses SQL aggregate functions to efficiently compute the overall bounds without
     * having to examine each geometry.
     *
     * @param featureType The feature type containing a bbox column
     * @param cx Database connection to use for querying
     * @return The computed bounds as a ReferencedEnvelope
     * @throws SQLException If there's an error executing SQL
     * @throws IOException If there's an error accessing the data
     */
    private ReferencedEnvelope computeBoundsFromBboxColumn(SimpleFeatureType featureType, Connection cx)
            throws SQLException, IOException {

        String sql = format(
                "SELECT ST_AsWKB(ST_MakeEnvelope(MIN(bbox.xmin), MAX(bbox.xmax), MIN(bbox.ymin), MAX(bbox.ymax))::GEOMETRY)::BLOB FROM %s",
                escapeName(featureType.getTypeName()));

        try (PreparedStatement ps = cx.prepareStatement(sql);
                ResultSet rs = ps.executeQuery()) {
            rs.next();
            Geometry fullBounds = parseWKB(rs.getBlob(1));
            GeometryDescriptor geometryDescriptor = featureType.getGeometryDescriptor();
            CoordinateReferenceSystem crs = geometryDescriptor.getCoordinateReferenceSystem();
            return new ReferencedEnvelope(fullBounds.getEnvelopeInternal(), crs);
        }
    }

    /**
     * Gets the SRID (Spatial Reference ID) for a geometry column.
     *
     * <p>In GeoParquet, geometries are typically in EPSG:4326 (WGS84) coordinate system, so this method returns 4326 by
     * default. A future enhancement could extract the CRS from the 'geo' metadata field.
     *
     * @param schemaName The database schema (unused in GeoParquet)
     * @param tableName The table/view name
     * @param columnName The geometry column name
     * @param cx Database connection
     * @return The SRID of the geometry column (4326)
     */
    @Override
    public Integer getGeometrySRID(String schemaName, String tableName, String columnName, Connection cx)
            throws SQLException {

        return 4326;
    }
}
